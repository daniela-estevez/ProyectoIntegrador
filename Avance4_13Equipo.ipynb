{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniela-estevez/ProyectoIntegrador/blob/main/Avance4_13Equipo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avance 4. Modelos alternativos\n",
        "\n",
        "## Equipo 13\n",
        "\n",
        "## Alejandro García Hernández A01793812\n",
        "## Daniela Estevez Rodriguez A01793723\n",
        "## Carlos Alberto López Álvarez A01168193"
      ],
      "metadata": {
        "id": "bnHtyrAJCo3s"
      },
      "id": "bnHtyrAJCo3s"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivos\n",
        "\n",
        "En esta etapa el objetivo es construir múltiples modelos con lafinalidad de explorar y evaluar cuál de ellos proporciona el mejor rendimiento para resolver el problema que nos fue asignado. El ejercicio se centra en la elección de los modelos, su entrenamiento y configuración de hiperparámetros para mejorar el desempeño."
      ],
      "metadata": {
        "id": "HOPH-TEIDF6Z"
      },
      "id": "HOPH-TEIDF6Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Librerías"
      ],
      "metadata": {
        "id": "yrLd5hs1LZMY"
      },
      "id": "yrLd5hs1LZMY"
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "FxqiPB_ImQ5b"
      },
      "id": "FxqiPB_ImQ5b",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "584809fc-6ced-4e75-ab2d-42baca19672d",
      "metadata": {
        "id": "584809fc-6ced-4e75-ab2d-42baca19672d"
      },
      "outputs": [],
      "source": [
        "# Librerías a utilizar para el pre procesamiento.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías para la sección de modelos supervisados\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, GridSearchCV, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix,f1_score, accuracy_score, classification_report, recall_score, make_scorer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "from IPython.display import display\n",
        "from xgboost import plot_importance\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "e0IQnXOlrYOD"
      },
      "id": "e0IQnXOlrYOD",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías adicionales para la sección de modelos no-supervisados\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import silhouette_score"
      ],
      "metadata": {
        "id": "J8uOGp8yl9hC"
      },
      "id": "J8uOGp8yl9hC",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# El siguiente bloque se agregó para poder leer los archivos drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#%cd /content/drive/MyDrive/Colab Notebooks/Proyecto Integrador"
      ],
      "metadata": {
        "id": "HtYYTTYS5nvS"
      },
      "id": "HtYYTTYS5nvS",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preparación de datos"
      ],
      "metadata": {
        "id": "4oIRZ5ycHAh0"
      },
      "id": "4oIRZ5ycHAh0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica el pre procesamiento de los datos que se ha trabajado en semanas anteriores"
      ],
      "metadata": {
        "id": "rYyJMawgi4wt"
      },
      "id": "rYyJMawgi4wt"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5bef599b-eb4f-4d50-964f-451b7065f29a",
      "metadata": {
        "id": "5bef599b-eb4f-4d50-964f-451b7065f29a"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"base_1.csv\",sep=\",\", encoding=\"latin1\")\n",
        "df= data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos entonces estas características\n",
        "df = df.drop([\"Nombre\",\"residencia\",\"fecha_nacimiento\",\"fecha_1er_visita\",\"FECHA_INICIO_ACTUAL_EPISODIO\"], axis=1)\n",
        "df = df.dropna(axis=1, how='all')"
      ],
      "metadata": {
        "id": "esYdsyF6PVJs"
      },
      "id": "esYdsyF6PVJs",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos el porcentaje de valores nulos en cada columna\n",
        "null_percentage = (df.isnull().sum() / len(df)) * 100\n",
        "\n",
        "# Con el sguiente código, se crea un DataFrame con los porcentajes de valores nulos\n",
        "null_df = pd.DataFrame({'Columna': null_percentage.index, 'Porcentaje_Null': null_percentage.values})\n",
        "\n",
        "# Filtramos el DataFrame para mantener solo las columnas donde el porcentaje de valores nulos sea menor al 40%\n",
        "columnas_a_mantener = null_df[null_df['Porcentaje_Null'] < 40]['Columna']\n",
        "\n",
        "# Filtramos el DataFrame original para mantener solo las columnas que queremos conservar\n",
        "df = df[columnas_a_mantener]"
      ],
      "metadata": {
        "id": "aDLQ8X1Tozmn"
      },
      "id": "aDLQ8X1Tozmn",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Primero obtenemos las variables que reportan un solo valor y mostramos sus nombres\n",
        "unique_counts = df.nunique()\n",
        "columnas_a_eliminar = unique_counts[unique_counts == 1].index\n",
        "columnas_a_eliminar\n",
        "df = df.drop(columns=columnas_a_eliminar)"
      ],
      "metadata": {
        "id": "MJTeBL1fmCEs"
      },
      "id": "MJTeBL1fmCEs",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_columns = []\n",
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    if len(unique_values) == 2 and all(value in [0, 1] for value in unique_values):\n",
        "        binary_columns.append(column)\n",
        "\n",
        "# Número de columnas con solamente 0's o 1's\n",
        "print(\"Numero de columnas binarias encontradas:\", len(binary_columns))"
      ],
      "metadata": {
        "id": "thcVkgNcRmfE",
        "outputId": "cf187aa4-87ec-4a6c-80c7-73b0b60b86a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "thcVkgNcRmfE",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero de columnas binarias encontradas: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Actualizamos el tipo de las columnas binarias a booleano usando astype()\n",
        "for column in binary_columns:\n",
        "    df[column] = df[column].astype(bool)"
      ],
      "metadata": {
        "id": "cXeYMB32SnjY"
      },
      "id": "cXeYMB32SnjY",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de variables que son en realidad categóricas\n",
        "cat_cols=[\"SEXO\",\"CONDICION_ACTUAL\",\"ESTADO_civil\",\"RELIGION\",\"PROVEEDOR_FAMILIAR\",\"OCUPACIoN_JEFE_FAMILIA\",\"ESCOLARIDAD__JEFE_FAMILIA\",\n",
        "         \"ESCOLARIDAD_MAXIMA_PX\",\"DX_PRIMARIO\",\"CODIGO_DX.1\",\"TRASTORNO_MAYOR_DIAGNOSTICO\",\n",
        "         \"Riesgo_suicidio\",\"Sintomas_ansiosos\"]\n",
        "\n",
        "# Actualizamos el tipo de las columnas categoricas usando astype()\n",
        "for column in cat_cols:\n",
        "    df[column] = df[column].astype(\"category\")"
      ],
      "metadata": {
        "id": "Sh7ne_k76UWz"
      },
      "id": "Sh7ne_k76UWz",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actualizamos el tipo de la columna MENARCA a uno numérico usando astype()\n",
        "df[\"MENARCA\"] = df[\"MENARCA\"].astype(\"float64\")"
      ],
      "metadata": {
        "id": "LwFz8w-Q89Cj"
      },
      "id": "LwFz8w-Q89Cj",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sustituir los valores de MENARCA donde SEXO es \"M\"\n",
        "df.loc[df['SEXO'] == 'M', 'MENARCA'] = -1\n",
        "\n",
        "# Imputar la moda a las variables numéricas\n",
        "for columna in df.select_dtypes(include='number').columns:\n",
        "    df[columna] = df[columna].fillna(df[columna].median())\n",
        "\n",
        "# Imputar la moda a las variables booleanas\n",
        "for columna in df.select_dtypes(include='bool').columns:\n",
        "    moda = df[columna].mode()[0]  # Calcular la moda\n",
        "    df[columna] = df[columna].fillna(moda)\n",
        "\n",
        "# Imputar la moda a las variables alfanuméricas\n",
        "for columna in df.select_dtypes(include='category').columns:\n",
        "    moda = df[columna].mode()[0]  # Calcular la moda\n",
        "    df[columna] = df[columna].fillna(moda)"
      ],
      "metadata": {
        "id": "NTUrQhJ0yUqB"
      },
      "id": "NTUrQhJ0yUqB",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de variables que son en realidad enteros\n",
        "enteros_cols=[\"EDAD_1era_visita\",\"EDAD_INICIO_1er_EPISODIO\",\"AnioS_ESTUDIO_PACIENTE\",\"MENARCA\",\"INICIO_VIDA_SEXUAL_ACTIVA\",\"MADRS_TOTAL\",\"CGI-S.1\"]\n",
        "\n",
        "# Actualizamos el tipo de las columnas de enteros usando astype()\n",
        "for column in enteros_cols:\n",
        "    df[column] = df[column].astype(\"int64\")"
      ],
      "metadata": {
        "id": "i-Z1k2A5_HMW"
      },
      "id": "i-Z1k2A5_HMW",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos estas características\n",
        "df = df.drop([\"EPISODIO_MAYOR_total_vida\",\"SUICIDALIDAD_ACTUAL\",\"SUICIDALIDAD_INTENTO_total_vida\",\n",
        "              \"B1b_INTENCION_DE_MORIR_EN_ACCIDENTE\",\"B5_PENSO_METODO_SUICIDARSE\",\"B8_PENSO_FECHA_SUICIDIO\",\n",
        "              \"B10_INTENCION_SUICIDIO\",\"B18_INTENTO_SUICIDARSE\",\"B2_NECESIDAD_DE_ESTAR_MUERTO\",\"TRASTORNO_MAYOR_PASADO\"],\n",
        "             axis=1)"
      ],
      "metadata": {
        "id": "8hhEnd6h2pzf"
      },
      "id": "8hhEnd6h2pzf",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos estas características\n",
        "df = df.drop([\"CODIGO_DX.1\",\"Puntaje_experto\"],\n",
        "             axis=1)"
      ],
      "metadata": {
        "id": "6ivNtjiUPnqV"
      },
      "id": "6ivNtjiUPnqV",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reemplazar el valor 1955 por la mediana\n",
        "df['EDAD_INICIO_1er_EPISODIO'] = df['EDAD_INICIO_1er_EPISODIO'].replace(1955, df['EDAD_INICIO_1er_EPISODIO'].median())\n",
        "\n",
        "# Reemplazar el valor 1 por la mediana\n",
        "df['INICIO_VIDA_SEXUAL_ACTIVA'] = df['INICIO_VIDA_SEXUAL_ACTIVA'].replace(1, df['INICIO_VIDA_SEXUAL_ACTIVA'].median())"
      ],
      "metadata": {
        "id": "XNERi1gd5zCE"
      },
      "id": "XNERi1gd5zCE",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos una copia del df para realizar una trasnformación\n",
        "df_T=df.copy()"
      ],
      "metadata": {
        "id": "E0shO5sixh2O"
      },
      "id": "E0shO5sixh2O",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Winsonorización:** Reemplaza los valores atípicos con valores en el percentil p-ésimo o (1 - p)-ésimo para reducir su impacto sin eliminarlos."
      ],
      "metadata": {
        "id": "ollbfoh41Bd3"
      },
      "id": "ollbfoh41Bd3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformamos las variables usando Winsonorización\n",
        "df_T['INICIO_VIDA_SEXUAL_ACTIVA_W'] = winsorize(df_T['INICIO_VIDA_SEXUAL_ACTIVA'], limits=(0.05, 0.05))\n",
        "df_T['DURACION_EPISODIO_MAYOR_ACTUAL_W'] = winsorize(df_T['DURACION_EPISODIO_MAYOR_ACTUAL'], limits=(0.05, 0.05))"
      ],
      "metadata": {
        "id": "qQUCHi2g0zJm"
      },
      "id": "qQUCHi2g0zJm",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos estas características originales\n",
        "df_T = df_T.drop([\"INICIO_VIDA_SEXUAL_ACTIVA\",\"DURACION_EPISODIO_MAYOR_ACTUAL\"],\n",
        "             axis=1)"
      ],
      "metadata": {
        "id": "3B5IIskH2EJ8"
      },
      "id": "3B5IIskH2EJ8",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos listas de las variables ordinales\n",
        "cat_orginales= ['ESCOLARIDAD__JEFE_FAMILIA', 'ESCOLARIDAD_MAXIMA_PX', 'DX_PRIMARIO','TRASTORNO_MAYOR_DIAGNOSTICO',\n",
        "                'Riesgo_suicidio','Sintomas_ansiosos']"
      ],
      "metadata": {
        "id": "U7psvMyVncZ8"
      },
      "id": "U7psvMyVncZ8",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una copia del dataframe\n",
        "df_TC=df_T.copy()"
      ],
      "metadata": {
        "id": "n4PyV3p9FmBR"
      },
      "id": "n4PyV3p9FmBR",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el encoder ordinal\n",
        "encoder_1 = OrdinalEncoder(categories=[[\"Menos de 6 años\", \"Primaria\", \"Secundaria\", \"Preparatoria\",\n",
        "                                     \"Estudios universitarios no terminados\", \"Licenciatura\", \"Posgrado\"]], dtype=int)\n",
        "encoder_2 = OrdinalEncoder(categories=[[\"Distimia\",\"Trastorno depresivo episodio único \",\n",
        "                                        \"Trastorno depresivo mayor recidivante\"]], dtype=int)\n",
        "encoder_3 = OrdinalEncoder(categories=[[\"0\",\"TRASTORNO DEPRESIVO MAYOR EPISODIO UNICO\",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR PRIMER EPISODIO\",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR RECURRENTE\",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR RECIDIVANTE \",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR RECURRENTE RESISTENTE\",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR RECURRENTE SEVERO\",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR\"]], dtype=int)\n",
        "encoder_4 = OrdinalEncoder(categories=[[\"Leve\",\"Moderado\",\"Alto\"]], dtype=int)\n",
        "encoder_5 = OrdinalEncoder(categories=[[\"Leve\",\"Moderado-Grave\"]], dtype=int)\n",
        "encoder_6 = OrdinalEncoder(categories=[[\"Primera aparición sin antecedente\",\"Indistinguible del pasado\",\n",
        "                                        \"Recurrencia condición previa\",\n",
        "                                        \"Significativamente diferente de condición previa\",\n",
        "                                        \"Exageración de trastorno crónico\"]], dtype=int)\n",
        "\n",
        "# Ajustar y transformar los datos\n",
        "df_TC['ESCOLARIDAD__JEFE_FAMILIA_encoded'] = encoder_1.fit_transform(df_TC[['ESCOLARIDAD__JEFE_FAMILIA']])\n",
        "df_TC['ESCOLARIDAD_MAXIMA_PX_encoded'] = encoder_1.fit_transform(df_TC[['ESCOLARIDAD_MAXIMA_PX']])\n",
        "df_TC['DX_PRIMARIO_encoded'] = encoder_2.fit_transform(df_TC[['DX_PRIMARIO']])\n",
        "df_TC['TRASTORNO_MAYOR_DIAGNOSTICO_encoded'] = encoder_3.fit_transform(df_TC[['TRASTORNO_MAYOR_DIAGNOSTICO']])\n",
        "df_TC['Riesgo_suicidio_encoded'] = encoder_4.fit_transform(df_TC[['Riesgo_suicidio']])\n",
        "df_TC['Sintomas_ansiosos_encoded'] = encoder_5.fit_transform(df_TC[['Sintomas_ansiosos']])\n",
        "df_TC['CONDICION_ACTUAL_encoded'] = encoder_6.fit_transform(df_TC[['CONDICION_ACTUAL']])"
      ],
      "metadata": {
        "id": "fF7ve2zfCYHG"
      },
      "id": "fF7ve2zfCYHG",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos estas características originales\n",
        "df_TC = df_TC.drop([\"ESCOLARIDAD__JEFE_FAMILIA\",\"ESCOLARIDAD_MAXIMA_PX\",\"DX_PRIMARIO\",\"TRASTORNO_MAYOR_DIAGNOSTICO\",\n",
        "                \"Riesgo_suicidio\",\"Sintomas_ansiosos\",\"CONDICION_ACTUAL\"],\n",
        "             axis=1)"
      ],
      "metadata": {
        "id": "D2-XKzz-DKuI"
      },
      "id": "D2-XKzz-DKuI",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos listas de las variables no ordinales\n",
        "cat_no_orginales= ['SEXO', 'ESTADO_civil', 'RELIGION','PROVEEDOR_FAMILIAR', 'OCUPACIoN_JEFE_FAMILIA']"
      ],
      "metadata": {
        "id": "73NCIXxVJ17m"
      },
      "id": "73NCIXxVJ17m",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una copia del ultimo dataframe\n",
        "df_TCL=df_TC.copy()"
      ],
      "metadata": {
        "id": "oH_Ynl1uKwNm"
      },
      "id": "oH_Ynl1uKwNm",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar el LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Iterar sobre las columnas y aplicar el LabelEncoder\n",
        "for col in cat_no_orginales:\n",
        "    df_TCL[col] = encoder.fit_transform(df_TCL[col])"
      ],
      "metadata": {
        "id": "wq4GGnTPJ-2O"
      },
      "id": "wq4GGnTPJ-2O",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una copia del ultimo dataframe\n",
        "df_TC_encoded=df_TC.copy()"
      ],
      "metadata": {
        "id": "yAoibeaaLwUV"
      },
      "id": "yAoibeaaLwUV",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar Get_dummies asegurando de eliminar la primera categoría\n",
        "df_TC_encoded = pd.get_dummies(df_TC_encoded, columns=cat_no_orginales, drop_first=True)"
      ],
      "metadata": {
        "id": "VDqQrNrSLI67"
      },
      "id": "VDqQrNrSLI67",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Modelos supervisados"
      ],
      "metadata": {
        "id": "nDfq3k1O-bp6"
      },
      "id": "nDfq3k1O-bp6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comanzaremos con una observación importante, el proyecto con el que estamos trabajando tiene que ver con la salud mental y física de pacientes, por lo que la métrica más adecuada para nuestros fines será **RECALL**, con el objetivo de evitar los falsos negativos en la medida de lo posible. No obstante, también mostraremos la métrica F1 como referencia para que, de ser posible y sin ser el objetivo principal, se minimicen los falsos positivos.\n",
        "\n",
        "Para esta etapa del proyecto profundizamos un poco más en los 7 modelos supervisados que elegimos probar.\n",
        "\n",
        "* **Regresión logística.** Este es un modelo simple y fácil de interpretar. Además, el modelo obtiene las probabilidades de pertenencia a cada clase, lo que puede servir para realizar umbrales más laxos o reestrictivos.\n",
        "* **SVM.** Este algoritmo funciona bien aún con un número grande de características y, aunque la base con dummies no es gigante, al final tenemos 69 variables.\n",
        "* **KNN.** Fácil entender e implementar.\n",
        "* **Árbol de Decisión.** Elefimos este porque es muy fácil de interpretar y se puede visualizar, además de que funciona bastante bien sin la necesidad de realizar tantas transformaciones a los datos, lo que muchas veces dificulta la interpretación.\n",
        "* **Bosque Aleatorio.** Al realizar la agregación de múltiples árboles de decisión, ayuda a reducir el riesgo de sobreajuste.\n",
        "* **Red neuronal.** Este algoritmo es potente para problemas con relaciones no lineales y complejas al descubrir patrones complejos. No obstante, su interpretación no es transparente.\n",
        "* **XGBoost.** Este algoritmo suele obtener una precisión muy alta y con el uso de boosting evita el sobreajuste y mejorara la generalización en datos no vistos. Gracias a lo anterior con este algoritmo se han ganado muchas competiciones de machine learning.\n",
        "\n",
        "Dividimos los modelos anteriores en dos grupos, ya que algunos de ellos necesitan que los datos tengan algunas transformaciones particulares para poder procesar y modelar adecuadamente la información de las variables categóricas en sus cálculos y predicciones.\n",
        "\n",
        "Para todos los modelos, con el refinamiento de los hiperparámetros buscamos obtener el mejor rendimiento posible sin caer en el sobreajuste. Además, dado que tenemos un ligero desbalance de las clases y, que los datos tiene que ver con la salud mental y física de pacientes, consideramos que es importante revisar el rendimiento de cada una de las clases dentro de los modelos. Para este fin, además del recall, obtendremos esta misma métrica utilizando macro-avg, ya que de esta manera, el recall se calcula primero para cada clase y luego se promedia, lo que garantiza que ambas clases tengan la misma importancia. Lo anterior, ayuda a evitar que el modelo preste menos atención a la clase minoritaria, que es justo donde más nos interesa minimizar los falsos negativos."
      ],
      "metadata": {
        "id": "32Hynfnjy-tk"
      },
      "id": "32Hynfnjy-tk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Regresión logística, SVM y KNN"
      ],
      "metadata": {
        "id": "sZm-rIy4H5Q8"
      },
      "id": "sZm-rIy4H5Q8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para estos modelos utilizaremos la base con variables dummies, observamos que esta base consta de 69 variables y 380 observaciones"
      ],
      "metadata": {
        "id": "1LT4CqbR7CTH"
      },
      "id": "1LT4CqbR7CTH"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataframe usando get dummies tiene {df_TC_encoded.shape[1]} columnas.\")\n",
        "print(f\"Dataframe usando get dummies tiene {df_TC_encoded.shape[0]} renglones.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky2oZZpUwp_t",
        "outputId": "c77f040d-31ff-4659-f723-553a6152084f"
      },
      "id": "Ky2oZZpUwp_t",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe usando get dummies tiene 69 columnas.\n",
            "Dataframe usando get dummies tiene 380 renglones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generamos la base con las características y la variable de salida\n",
        "X1 = df_TC_encoded.drop(columns=['Sintomas_ansiosos_encoded'])\n",
        "Y1 = df_TC_encoded['Sintomas_ansiosos_encoded']"
      ],
      "metadata": {
        "id": "a-4u7zefwCJ8"
      },
      "id": "a-4u7zefwCJ8",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque nuestra base es pequeña, debemos de dividirla para obtener datos de entrenamiento y validación. Así, usaremos el 90% de los datos para entrenar los modelos."
      ],
      "metadata": {
        "id": "isTyiFIO7qfI"
      },
      "id": "isTyiFIO7qfI"
    },
    {
      "cell_type": "code",
      "source": [
        "Xtv1, Xtest1, ytv1, ytest1 = train_test_split(X1, Y1, train_size = 0.9, random_state = 0)"
      ],
      "metadata": {
        "id": "K0aNz3m8sRFV"
      },
      "id": "K0aNz3m8sRFV",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1 Regresión logística"
      ],
      "metadata": {
        "id": "o0DY_0cBwIPE"
      },
      "id": "o0DY_0cBwIPE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "reg = LogisticRegression(solver='liblinear', class_weight= \"balanced\", random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2', 'none'],\n",
        "    'max_iter': [100, 200, 300],\n",
        "    'tol': [1e-4, 1e-3, 1e-2, 1e-1]\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=reg,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv1, ytv1)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv1_pred = cross_val_predict(grid.best_estimator_, Xtv1, ytv1, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv1, ytv1_pred)\n",
        "recall_tv = recall_score(ytv1, ytv1_pred, average='binary')\n",
        "recall_tv_macro = recall_score(ytv1, ytv1_pred, average='macro')\n",
        "f1_tv = f1_score(ytv1, ytv1_pred, average='binary')\n",
        "f1_tv_macro = f1_score(ytv1, ytv1_pred, average='macro')\n",
        "cm_tv = confusion_matrix(ytv1, ytv1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest1_pred = grid.best_estimator_.predict(Xtest1)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest1, ytest1_pred)\n",
        "recall_test = recall_score(ytest1, ytest1_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest1, ytest1_pred, average='macro')\n",
        "f1_test = f1_score(ytest1, ytest1_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest1, ytest1_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest1, ytest1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrsOVi7EuaoN",
        "outputId": "d0c218d2-82a5-40f0-fc07-1b690cad1f7c"
      },
      "id": "FrsOVi7EuaoN",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.5614\n",
            "Recall: 0.5882\n",
            "Recall macro: 0.5503\n",
            "F1: 0.6341\n",
            "F1 macro: 0.5434\n",
            "Matriz de confusión:\n",
            "[[ 62  59]\n",
            " [ 91 130]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.6053\n",
            "Recall: 0.6667\n",
            "Recall macro: 0.5833\n",
            "F1: 0.6809\n",
            "F1 macro: 0.5818\n",
            "Matriz de confusión:\n",
            "[[ 7  7]\n",
            " [ 8 16]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2 SVM"
      ],
      "metadata": {
        "id": "1PJFmKvW91PL"
      },
      "id": "1PJFmKvW91PL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "svm = SVC(class_weight='balanced',random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1],\n",
        "#    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
        "    'gamma': [0.001, 0.01, 0.1],\n",
        "#    'degree': [2, 3, 4]\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=svm,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv1, ytv1)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv1_pred = cross_val_predict(grid.best_estimator_, Xtv1, ytv1, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv1, ytv1_pred)\n",
        "recall_tv = recall_score(ytv1, ytv1_pred, average='binary')\n",
        "recall_tv_macro = recall_score(ytv1, ytv1_pred, average='macro')\n",
        "f1_tv = f1_score(ytv1, ytv1_pred, average='binary')\n",
        "f1_tv_macro = f1_score(ytv1, ytv1_pred, average='macro')\n",
        "cm_tv = confusion_matrix(ytv1, ytv1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest1_pred = grid.best_estimator_.predict(Xtest1)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest1, ytest1_pred)\n",
        "recall_test = recall_score(ytest1, ytest1_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest1, ytest1_pred, average='macro')\n",
        "f1_test = f1_score(ytest1, ytest1_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest1, ytest1_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest1, ytest1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnwt7-oF95wa",
        "outputId": "b9c3239e-be09-4dd0-a2e9-10f9f3188675"
      },
      "id": "jnwt7-oF95wa",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.5906\n",
            "Recall: 0.5656\n",
            "Recall macro: 0.6010\n",
            "F1: 0.6410\n",
            "F1 macro: 0.5824\n",
            "Matriz de confusión:\n",
            "[[ 77  44]\n",
            " [ 96 125]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.6316\n",
            "Recall: 0.5833\n",
            "Recall macro: 0.6488\n",
            "F1: 0.6667\n",
            "F1 macro: 0.6275\n",
            "Matriz de confusión:\n",
            "[[10  4]\n",
            " [10 14]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.3 KNN"
      ],
      "metadata": {
        "id": "YFmBsXgkGPgT"
      },
      "id": "YFmBsXgkGPgT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=knn,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv1, ytv1)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv1_pred = cross_val_predict(grid.best_estimator_, Xtv1, ytv1, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv1, ytv1_pred)\n",
        "recall_tv = recall_score(ytv1, ytv1_pred, average='binary')\n",
        "recall_tv_macro = recall_score(ytv1, ytv1_pred, average='macro')\n",
        "f1_tv = f1_score(ytv1, ytv1_pred, average='binary')\n",
        "f1_tv_macro = f1_score(ytv1, ytv1_pred, average='macro')\n",
        "cm_tv = confusion_matrix(ytv1, ytv1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest1_pred = grid.best_estimator_.predict(Xtest1)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest1, ytest1_pred)\n",
        "recall_test = recall_score(ytest1, ytest1_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest1, ytest1_pred, average='macro')\n",
        "f1_test = f1_score(ytest1, ytest1_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest1, ytest1_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest1, ytest1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCFNfGe8GR45",
        "outputId": "2df55648-9cde-46fc-804f-27f2d0ab2e6c"
      },
      "id": "SCFNfGe8GR45",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.6257\n",
            "Recall: 0.7828\n",
            "Recall macro: 0.5608\n",
            "F1: 0.7300\n",
            "F1 macro: 0.5602\n",
            "Matriz de confusión:\n",
            "[[ 41  80]\n",
            " [ 48 173]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.5263\n",
            "Recall: 0.6667\n",
            "Recall macro: 0.4762\n",
            "F1: 0.6400\n",
            "F1 macro: 0.4738\n",
            "Matriz de confusión:\n",
            "[[ 4 10]\n",
            " [ 8 16]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Árbol de decisión, Bosque aleatorio, Red neuronal, XGBoost"
      ],
      "metadata": {
        "id": "s8psjMu9HgO_"
      },
      "id": "s8psjMu9HgO_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora probaremos con otro tipo de modelos en los que no es necesario utilizar variables dummies. Observamos que esta base consta de 39 variables y 380 observaciones"
      ],
      "metadata": {
        "id": "pq8WZBjgHrJd"
      },
      "id": "pq8WZBjgHrJd"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataframe usando label ecoding tiene {df_TCL.shape[1]} columnas.\")\n",
        "print(f\"Dataframe usando label ecoding tiene {df_TCL.shape[0]} renglones.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o7_VkwLHvOa",
        "outputId": "0a26e901-cebe-49c3-f350-19f77aabf4ef"
      },
      "id": "_o7_VkwLHvOa",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe usando label ecoding tiene 39 columnas.\n",
            "Dataframe usando label ecoding tiene 380 renglones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generamos la base con las características y la variable de salida\n",
        "X2 = df_TCL.drop(columns=['Sintomas_ansiosos_encoded'])\n",
        "Y2 = df_TCL['Sintomas_ansiosos_encoded']"
      ],
      "metadata": {
        "id": "s45wkU0HH6uh"
      },
      "id": "s45wkU0HH6uh",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como ya explicamos anteriormente, utilizaremos el 90% de los datos para el entrenamiento además de validación cruzada."
      ],
      "metadata": {
        "id": "akHik_TjH7uS"
      },
      "id": "akHik_TjH7uS"
    },
    {
      "cell_type": "code",
      "source": [
        "Xtv2, Xtest2, ytv2, ytest2 = train_test_split(X2, Y2, train_size = 0.9, random_state = 0)"
      ],
      "metadata": {
        "id": "1KrMnEPvH6w5"
      },
      "id": "1KrMnEPvH6w5",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1 Árbol de decisión"
      ],
      "metadata": {
        "id": "qgE2uXSAHjsG"
      },
      "id": "qgE2uXSAHjsG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "arbol = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_split': [7, 10, 15],\n",
        "    'min_samples_leaf': [7, 10, 15],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=arbol,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv2, ytv2)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv2_pred = cross_val_predict(grid.best_estimator_, Xtv2, ytv2, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv2, ytv2_pred)\n",
        "recall_tv = recall_score(ytv2, ytv2_pred, average='binary')\n",
        "recall_tv_macro = recall_score(ytv2, ytv2_pred, average='macro')\n",
        "f1_tv = f1_score(ytv2, ytv2_pred, average='binary')\n",
        "f1_tv_macro = f1_score(ytv2, ytv2_pred, average='macro')\n",
        "cm_tv = confusion_matrix(ytv2, ytv2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest2_pred = grid.best_estimator_.predict(Xtest2)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest2, ytest2_pred)\n",
        "recall_test = recall_score(ytest2, ytest2_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest2, ytest2_pred, average='macro')\n",
        "f1_test = f1_score(ytest2, ytest2_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest2, ytest2_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest2, ytest2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uNE9YV4KGlQ",
        "outputId": "83ad499e-1b63-44b7-83a5-977d09f48517"
      },
      "id": "9uNE9YV4KGlQ",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 7}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.5906\n",
            "Recall: 0.6878\n",
            "Recall macro: 0.5505\n",
            "F1: 0.6847\n",
            "F1 macro: 0.5507\n",
            "Matriz de confusión:\n",
            "[[ 50  71]\n",
            " [ 69 152]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.6053\n",
            "Recall: 0.7917\n",
            "Recall macro: 0.5387\n",
            "F1: 0.7170\n",
            "F1 macro: 0.5324\n",
            "Matriz de confusión:\n",
            "[[ 4 10]\n",
            " [ 5 19]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2 Bosque aleatorio"
      ],
      "metadata": {
        "id": "So9HF0T7J4bJ"
      },
      "id": "So9HF0T7J4bJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "bosque = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_split': [7, 10, 15],\n",
        "    'min_samples_leaf': [7, 10, 15],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=bosque,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv2, ytv2)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv2_pred = cross_val_predict(grid.best_estimator_, Xtv2, ytv2, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv2, ytv2_pred)\n",
        "recall_tv = recall_score(ytv2, ytv2_pred, average='binary')\n",
        "recall_tv_macro = recall_score(ytv2, ytv2_pred, average='macro')\n",
        "f1_tv = f1_score(ytv2, ytv2_pred, average='binary')\n",
        "f1_tv_macro = f1_score(ytv2, ytv2_pred, average='macro')\n",
        "cm_tv = confusion_matrix(ytv2, ytv2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest2_pred = grid.best_estimator_.predict(Xtest2)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest2, ytest2_pred)\n",
        "recall_test = recall_score(ytest2, ytest2_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest2, ytest2_pred, average='macro')\n",
        "f1_test = f1_score(ytest2, ytest2_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest2, ytest2_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest2, ytest2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptKvu9WLHbTB",
        "outputId": "eb51d6a3-fac8-49d7-c6f1-1dd5f3a35593"
      },
      "id": "ptKvu9WLHbTB",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 7, 'min_samples_split': 7, 'n_estimators': 50}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.6404\n",
            "Recall: 0.8733\n",
            "Recall macro: 0.5441\n",
            "F1: 0.7583\n",
            "F1 macro: 0.5277\n",
            "Matriz de confusión:\n",
            "[[ 26  95]\n",
            " [ 28 193]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.6316\n",
            "Recall: 0.9583\n",
            "Recall macro: 0.5149\n",
            "F1: 0.7667\n",
            "F1 macro: 0.4458\n",
            "Matriz de confusión:\n",
            "[[ 1 13]\n",
            " [ 1 23]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.3 Red neuronal"
      ],
      "metadata": {
        "id": "0qsWeT2MWVLE"
      },
      "id": "0qsWeT2MWVLE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "red = MLPClassifier(solver=\"adam\", random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
        "    'activation': ['logistic', 'tanh', 'relu'],\n",
        "    'alpha': [0.001, 0.01, 0.1],\n",
        "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
        "    'max_iter': [500, 1000, 3000]\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=red,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv2, ytv2)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv2_pred = cross_val_predict(grid.best_estimator_, Xtv2, ytv2, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv2, ytv2_pred)\n",
        "recall_tv = recall_score(ytv2, ytv2_pred, average='binary')\n",
        "recall_tv_macro = recall_score(ytv2, ytv2_pred, average='macro')\n",
        "f1_tv = f1_score(ytv2, ytv2_pred, average='binary')\n",
        "f1_tv_macro = f1_score(ytv2, ytv2_pred, average='macro')\n",
        "cm_tv = confusion_matrix(ytv2, ytv2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest2_pred = grid.best_estimator_.predict(Xtest2)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest2, ytest2_pred)\n",
        "recall_test = recall_score(ytest2, ytest2_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest2, ytest2_pred, average='macro')\n",
        "f1_test = f1_score(ytest2, ytest2_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest2, ytest2_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest2, ytest2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "id": "_u-o-gR6HbV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e2ce3c-484c-4506-d8d0-80926dd4c03f"
      },
      "id": "_u-o-gR6HbV5",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01, 'max_iter': 500}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.5702\n",
            "Recall: 0.6787\n",
            "Recall macro: 0.5253\n",
            "F1: 0.6711\n",
            "F1 macro: 0.5254\n",
            "Matriz de confusión:\n",
            "[[ 45  76]\n",
            " [ 71 150]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.5789\n",
            "Recall: 0.6667\n",
            "Recall macro: 0.5476\n",
            "F1: 0.6667\n",
            "F1 macro: 0.5476\n",
            "Matriz de confusión:\n",
            "[[ 6  8]\n",
            " [ 8 16]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.4 XGBoost"
      ],
      "metadata": {
        "id": "oLyMzPr4PBZJ"
      },
      "id": "oLyMzPr4PBZJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "xgb = XGBClassifier(random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'min_child_weight': [1, 3, 5, 7],\n",
        "    'gamma': [0, 0.1, 0.2, 0.3],\n",
        "    'subsample': [0.6, 0.7, 0.8]\n",
        "#    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "#    'colsample_bylevel': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=xgb,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv2, ytv2)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv2_pred = cross_val_predict(grid.best_estimator_, Xtv2, ytv2, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv2, ytv2_pred)\n",
        "recall_tv = recall_score(ytv2, ytv2_pred, average='binary')\n",
        "recall_tv_macro = recall_score(ytv2, ytv2_pred, average='macro')\n",
        "f1_tv = f1_score(ytv2, ytv2_pred, average='binary')\n",
        "f1_tv_macro = f1_score(ytv2, ytv2_pred, average='macro')\n",
        "cm_tv = confusion_matrix(ytv2, ytv2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest2_pred = grid.best_estimator_.predict(Xtest2)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest2, ytest2_pred)\n",
        "recall_test = recall_score(ytest2, ytest2_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest2, ytest2_pred, average='macro')\n",
        "f1_test = f1_score(ytest2, ytest2_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest2, ytest2_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest2, ytest2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "id": "oo9c_BpMHbYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9cbacac-3af4-4657-eaf2-5e7d56ab9977"
      },
      "id": "oo9c_BpMHbYR",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 50, 'subsample': 0.6}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.6228\n",
            "Recall: 0.8145\n",
            "Recall macro: 0.5436\n",
            "F1: 0.7362\n",
            "F1 macro: 0.5373\n",
            "Matriz de confusión:\n",
            "[[ 33  88]\n",
            " [ 41 180]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.6316\n",
            "Recall: 0.8333\n",
            "Recall macro: 0.5595\n",
            "F1: 0.7407\n",
            "F1 macro: 0.5522\n",
            "Matriz de confusión:\n",
            "[[ 4 10]\n",
            " [ 4 20]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Conclusiones"
      ],
      "metadata": {
        "id": "c8oC5CN8aZYz"
      },
      "id": "c8oC5CN8aZYz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al ajustar los hiperparámetros de los 7 modelos supervisados elegidos, obtivimos diferentes resultados a los de la entrega anterior y no son comparables ya que la semana anterior, el entrenamiento se realizó utilizando recall como métrica de rendimiento y como ya explicamos, ahora utilizamos recall macro.\n",
        "\n",
        "Así, al realizar la busqueda de algunos de los mejores hiperparámetros:\n",
        "\n",
        "* Para la regresión logística obtuvimos un recall macro de 55% y 58% con el conjunto de entrenamiento y el de validación respectivamente, lo que nos indica que el modelo podría no estar generalizando bien los datos. Por su parte, también obtuvimos un recall bajo (59% entrenamiento y 67% prueba). De cualquier forma, el rendimiento del modelo fue pobre.\n",
        "\n",
        "* En cuanto a SVM obtenemos 60% de recall macro en el entrenamiento (57% de recall), y al utilizar los datos de prueba notamos que el rendimiento fue de 65% (58% de recall), con lo que el modelo tuvo un bajo rendimiento además de que podría no está generalizando bien los datos.\n",
        "\n",
        "* Con KNN obtuvimos un recall macro 56% y 48% de rendimiento con el conjunto de entrenamiento y el de validación respectivamente, lo que indica un problema de sobreentrenamiento. Este mismo comportamiento se observa con el recall (78% en entrenamiento y 66% en prueba).\n",
        "\n",
        "* Con árboles de decisión obtuvimos una recall macro de 55% y 54%, con los conjuntos de entrenamiento y prueba, respectivamente y un recall de 69% y 79% para los mismos conjuntos. Cuando entrenamos el árbol utilizando recall sin promediar en la validación cruzada obtenemos un recall de 93% y 92%, con los conjuntos de entrenamiento y prueba, aunque al ver la matriz de confusión de estos resultados parecería que el modelo se está enfocando casi completamente en la clase mayoritaria.\n",
        "\n",
        "* Con el bosque aleatorio tuvimos resultados parecidos al árbol de decisión. Obtuvimos un recall macro de 54% en el entrenamiento y 51% con el conjunto de prueba (87% y 96% de recall). Cuando entrenamos el modelo utilizando recall sin promediar en la validación cruzada obtenemos un recall de 97% y 96%, con los conjuntos de entrenamiento y prueba y un F1 de 78% con ambos conjuntos de datos, pero al igual que en el árbol de decisión, al ver la matriz de confusión de estos resultados parecería que el modelo se está enfocando casi completamente en la clase mayoritaria.\n",
        "\n",
        "* Con la red neuronal obtuvimos una recall macro de 53% y 55%, con los conjuntos de entrenamiento y prueba (68% y 67% de recall), con lo que este modelo tampoco obtuvo un buen rendimiento.\n",
        "\n",
        "* Finalmente, con XGBoost obtuvimos un recall macro de 54% y 56%, con los conjuntos de entrenamiento y prueba (81% y 83% de recall), por lo que tampoco obtuvimos buenos resultados.\n"
      ],
      "metadata": {
        "id": "f3f-vUnQtWg_"
      },
      "id": "f3f-vUnQtWg_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Otros"
      ],
      "metadata": {
        "id": "f6qVnj04l9Yq"
      },
      "id": "f6qVnj04l9Yq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si bien, en los modelos de las secciones previas se intentó moderar el efecto del ligero desbalance que existe en los datos mediante el uso de class_weight=\"balanced\", decidimos probar primero balanceando un poco más los datos mediante el uso de sobremuestreo, submuestreo y una combinación de ambos. A continuación, mostramos únicamente los mejores resultados, los cuales fueron obtenidos con submuestreo y dejando un desbalance de 40-60.  "
      ],
      "metadata": {
        "id": "Nstj-Jp_mGGq"
      },
      "id": "Nstj-Jp_mGGq"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "smote = SMOTE(random_state=0)\n",
        "undersampler = RandomUnderSampler(sampling_strategy=0.6667, random_state=0) #balanceando al 40-60\n",
        "smote_enn = SMOTEENN(random_state=0)\n",
        "\n",
        "Xtv1_res, Ytv1_res = undersampler.fit_resample(Xtv1, ytv1)"
      ],
      "metadata": {
        "id": "orPpG0c4cO6c"
      },
      "id": "orPpG0c4cO6c",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "reg = LogisticRegression(solver='liblinear', random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2', 'none'],\n",
        "    'max_iter': [100, 200, 300],\n",
        "    'tol': [1e-4, 1e-3, 1e-2, 1e-1]\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=reg,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv1_res, Ytv1_res)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv1_pred = cross_val_predict(grid.best_estimator_, Xtv1_res, Ytv1_res, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(Ytv1_res, ytv1_pred)\n",
        "recall_tv = recall_score(Ytv1_res, ytv1_pred, average='binary')\n",
        "recall_tv_macro = recall_score(Ytv1_res, ytv1_pred, average='macro')\n",
        "f1_tv = f1_score(Ytv1_res, ytv1_pred, average='binary')\n",
        "f1_tv_macro = f1_score(Ytv1_res, ytv1_pred, average='macro')\n",
        "cm_tv = confusion_matrix(Ytv1_res, ytv1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest1_pred = grid.best_estimator_.predict(Xtest1)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest1, ytest1_pred)\n",
        "recall_test = recall_score(ytest1, ytest1_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest1, ytest1_pred, average='macro')\n",
        "f1_test = f1_score(ytest1, ytest1_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest1, ytest1_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest1, ytest1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn4yOfFTcnJU",
        "outputId": "7ae99c56-9d61-46e1-9170-4020155cec49"
      },
      "id": "jn4yOfFTcnJU",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.5762\n",
            "Recall: 0.7182\n",
            "Recall macro: 0.5409\n",
            "F1: 0.6701\n",
            "F1 macro: 0.5388\n",
            "Matriz de confusión:\n",
            "[[ 44  77]\n",
            " [ 51 130]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.5263\n",
            "Recall: 0.6667\n",
            "Recall macro: 0.4762\n",
            "F1: 0.6400\n",
            "F1 macro: 0.4738\n",
            "Matriz de confusión:\n",
            "[[ 4 10]\n",
            " [ 8 16]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "svm = SVC(random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1],\n",
        "#    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
        "    'gamma': [0.001, 0.01, 0.1],\n",
        "#    'degree': [2, 3, 4]\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=svm,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv1_res, Ytv1_res)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv1_pred = cross_val_predict(grid.best_estimator_, Xtv1_res, Ytv1_res, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(Ytv1_res, ytv1_pred)\n",
        "recall_tv = recall_score(Ytv1_res, ytv1_pred, average='binary')\n",
        "recall_tv_macro = recall_score(Ytv1_res, ytv1_pred, average='macro')\n",
        "f1_tv = f1_score(Ytv1_res, ytv1_pred, average='binary')\n",
        "f1_tv_macro = f1_score(Ytv1_res, ytv1_pred, average='macro')\n",
        "cm_tv = confusion_matrix(Ytv1_res, ytv1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest1_pred = grid.best_estimator_.predict(Xtest1)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest1, ytest1_pred)\n",
        "recall_test = recall_score(ytest1, ytest1_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest1, ytest1_pred, average='macro')\n",
        "f1_test = f1_score(ytest1, ytest1_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest1, ytest1_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest1, ytest1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szaIM55yeCMn",
        "outputId": "2e6e12f1-24d3-4e99-d93c-7c60ff5e3fad"
      },
      "id": "szaIM55yeCMn",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.6126\n",
            "Recall: 0.7680\n",
            "Recall macro: 0.5741\n",
            "F1: 0.7038\n",
            "F1 macro: 0.5720\n",
            "Matriz de confusión:\n",
            "[[ 46  75]\n",
            " [ 42 139]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.5526\n",
            "Recall: 0.7083\n",
            "Recall macro: 0.4970\n",
            "F1: 0.6667\n",
            "F1 macro: 0.4933\n",
            "Matriz de confusión:\n",
            "[[ 4 10]\n",
            " [ 7 17]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=knn,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv1_res, Ytv1_res)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv1_pred = cross_val_predict(grid.best_estimator_, Xtv1_res, Ytv1_res, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(Ytv1_res, ytv1_pred)\n",
        "recall_tv = recall_score(Ytv1_res, ytv1_pred, average='binary')\n",
        "recall_tv_macro = recall_score(Ytv1_res, ytv1_pred, average='macro')\n",
        "f1_tv = f1_score(Ytv1_res, ytv1_pred, average='binary')\n",
        "f1_tv_macro = f1_score(Ytv1_res, ytv1_pred, average='macro')\n",
        "cm_tv = confusion_matrix(Ytv1_res, ytv1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest1_pred = grid.best_estimator_.predict(Xtest1)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest1, ytest1_pred)\n",
        "recall_test = recall_score(ytest1, ytest1_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest1, ytest1_pred, average='macro')\n",
        "f1_test = f1_score(ytest1, ytest1_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest1, ytest1_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest1, ytest1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDfA3YGDeCSH",
        "outputId": "b559c965-53c1-4e35-9422-459049659e19"
      },
      "id": "MDfA3YGDeCSH",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.6159\n",
            "Recall: 0.6851\n",
            "Recall macro: 0.5987\n",
            "F1: 0.6813\n",
            "F1 macro: 0.5990\n",
            "Matriz de confusión:\n",
            "[[ 62  59]\n",
            " [ 57 124]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.5263\n",
            "Recall: 0.6250\n",
            "Recall macro: 0.4911\n",
            "F1: 0.6250\n",
            "F1 macro: 0.4911\n",
            "Matriz de confusión:\n",
            "[[ 5  9]\n",
            " [ 9 15]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#undersampler2 = RandomUnderSampler(sampling_strategy=0.818181, random_state=0)  #Intentando balancear al 45-55\n",
        "Xtv2_res, Ytv2_res = undersampler.fit_resample(Xtv2, ytv2)"
      ],
      "metadata": {
        "id": "jou-N3ohf7or"
      },
      "id": "jou-N3ohf7or",
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "arbol = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_split': [7, 10, 15],\n",
        "    'min_samples_leaf': [7, 10, 15],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=arbol,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv2_res, Ytv2_res)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv2_pred = cross_val_predict(grid.best_estimator_, Xtv2_res, Ytv2_res, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(Ytv2_res, ytv2_pred)\n",
        "recall_tv = recall_score(Ytv2_res, ytv2_pred, average='binary')\n",
        "recall_tv_macro = recall_score(Ytv2_res, ytv2_pred, average='macro')\n",
        "f1_tv = f1_score(Ytv2_res, ytv2_pred, average='binary')\n",
        "f1_tv_macro = f1_score(Ytv2_res, ytv2_pred, average='macro')\n",
        "cm_tv = confusion_matrix(Ytv2_res, ytv2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest2_pred = grid.best_estimator_.predict(Xtest2)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest2, ytest2_pred)\n",
        "recall_test = recall_score(ytest2, ytest2_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest2, ytest2_pred, average='macro')\n",
        "f1_test = f1_score(ytest2, ytest2_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest2, ytest2_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest2, ytest2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLHZphCPf7rS",
        "outputId": "a49bcce1-2a5c-4830-8e0e-5f025c43eb7c"
      },
      "id": "cLHZphCPf7rS",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 15, 'min_samples_split': 7}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.5563\n",
            "Recall: 0.6630\n",
            "Recall macro: 0.5298\n",
            "F1: 0.6417\n",
            "F1 macro: 0.5296\n",
            "Matriz de confusión:\n",
            "[[ 48  73]\n",
            " [ 61 120]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.5789\n",
            "Recall: 0.7917\n",
            "Recall macro: 0.5030\n",
            "F1: 0.7037\n",
            "F1 macro: 0.4882\n",
            "Matriz de confusión:\n",
            "[[ 3 11]\n",
            " [ 5 19]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "bosque = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_split': [7, 10, 15],\n",
        "    'min_samples_leaf': [7, 10, 15],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=bosque,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall_macro\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv2_res, Ytv2_res)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv2_pred = cross_val_predict(grid.best_estimator_, Xtv2_res, Ytv2_res, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(Ytv2_res, ytv2_pred)\n",
        "recall_tv = recall_score(Ytv2_res, ytv2_pred, average='binary')\n",
        "recall_tv_macro = recall_score(Ytv2_res, ytv2_pred, average='macro')\n",
        "f1_tv = f1_score(Ytv2_res, ytv2_pred, average='binary')\n",
        "f1_tv_macro = f1_score(Ytv2_res, ytv2_pred, average='macro')\n",
        "cm_tv = confusion_matrix(Ytv2_res, ytv2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"Recall macro: {recall_tv_macro:.4f}\")\n",
        "print(f\"F1: {f1_tv:.4f}\")\n",
        "print(f\"F1 macro: {f1_tv_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest2_pred = grid.best_estimator_.predict(Xtest2)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest2, ytest2_pred)\n",
        "recall_test = recall_score(ytest2, ytest2_pred, average='binary')\n",
        "recall_test_macro = recall_score(ytest2, ytest2_pred, average='macro')\n",
        "f1_test = f1_score(ytest2, ytest2_pred, average='binary')\n",
        "f1_test_macro = f1_score(ytest2, ytest2_pred, average='macro')\n",
        "cm_test = confusion_matrix(ytest2, ytest2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"Recall macro: {recall_test_macro:.4f}\")\n",
        "print(f\"F1: {f1_test:.4f}\")\n",
        "print(f\"F1 macro: {f1_test_macro:.4f}\")\n",
        "print(f'Matriz de confusión:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5M4IXeVlphw",
        "outputId": "634e5125-3746-461d-89fb-124bf147ff2d"
      },
      "id": "F5M4IXeVlphw",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'auto', 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 200}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.5993\n",
            "Recall: 0.8011\n",
            "Recall macro: 0.5493\n",
            "F1: 0.7056\n",
            "F1 macro: 0.5393\n",
            "Matriz de confusión:\n",
            "[[ 36  85]\n",
            " [ 36 145]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.6316\n",
            "Recall: 0.8333\n",
            "Recall macro: 0.5595\n",
            "F1: 0.7407\n",
            "F1 macro: 0.5522\n",
            "Matriz de confusión:\n",
            "[[ 4 10]\n",
            " [ 4 20]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorias, num = np.unique(ytv2, return_counts=True)\n",
        "\n",
        "for categorias, num in zip(categorias, num):\n",
        "    print(f\"Categoría {categorias}: {num} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJGuEQsmibWm",
        "outputId": "4ba017a1-ec30-4875-88ae-bb43ee530748"
      },
      "id": "nJGuEQsmibWm",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categoría 0: 121 \n",
            "Categoría 1: 221 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorias, num = np.unique(Ytv2_res, return_counts=True)\n",
        "\n",
        "for categorias, num in zip(categorias, num):\n",
        "    print(f\"Categoría {categorias}: {num} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anp1AuSff7tk",
        "outputId": "5e606426-a027-45f4-9faa-b5537fdd9d99"
      },
      "id": "anp1AuSff7tk",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categoría 0: 121 \n",
            "Categoría 1: 181 \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}