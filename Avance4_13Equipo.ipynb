{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniela-estevez/ProyectoIntegrador/blob/main/Avance4_13Equipo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avance 4. Modelos alternativos\n",
        "\n",
        "## Equipo 13\n",
        "\n",
        "## Alejandro García Hernández A01793812\n",
        "## Daniela Estevez Rodriguez A01793723\n",
        "## Carlos Alberto López Álvarez A01168193"
      ],
      "metadata": {
        "id": "bnHtyrAJCo3s"
      },
      "id": "bnHtyrAJCo3s"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivos\n",
        "\n",
        "En esta etapa el objetivo es construir múltiples modelos con lafinalidad de explorar y evaluar cuál de ellos proporciona el mejor rendimiento para resolver el problema que nos fue asignado. El ejercicio se centra en la elección de los modelos, su entrenamiento y configuración de hiperparámetros para mejorar el desempeño."
      ],
      "metadata": {
        "id": "HOPH-TEIDF6Z"
      },
      "id": "HOPH-TEIDF6Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Librerías"
      ],
      "metadata": {
        "id": "yrLd5hs1LZMY"
      },
      "id": "yrLd5hs1LZMY"
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "FxqiPB_ImQ5b"
      },
      "id": "FxqiPB_ImQ5b",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "584809fc-6ced-4e75-ab2d-42baca19672d",
      "metadata": {
        "id": "584809fc-6ced-4e75-ab2d-42baca19672d"
      },
      "outputs": [],
      "source": [
        "# Librerías a utilizar para el pre procesamiento.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías para la sección de modelos supervisados\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, GridSearchCV, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix,f1_score, accuracy_score, classification_report, recall_score, make_scorer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "from IPython.display import display\n",
        "from xgboost import plot_importance\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "e0IQnXOlrYOD"
      },
      "id": "e0IQnXOlrYOD",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías adicionales para la sección de modelos no-supervisados\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import silhouette_score"
      ],
      "metadata": {
        "id": "J8uOGp8yl9hC"
      },
      "id": "J8uOGp8yl9hC",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# El siguiente bloque se agregó para poder leer los archivos drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#%cd /content/drive/MyDrive/Colab Notebooks/Proyecto Integrador"
      ],
      "metadata": {
        "id": "HtYYTTYS5nvS"
      },
      "id": "HtYYTTYS5nvS",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preparación de datos"
      ],
      "metadata": {
        "id": "4oIRZ5ycHAh0"
      },
      "id": "4oIRZ5ycHAh0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica el pre procesamiento de los datos que se ha trabajado en semanas anteriores"
      ],
      "metadata": {
        "id": "rYyJMawgi4wt"
      },
      "id": "rYyJMawgi4wt"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5bef599b-eb4f-4d50-964f-451b7065f29a",
      "metadata": {
        "id": "5bef599b-eb4f-4d50-964f-451b7065f29a"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"base_1.csv\",sep=\",\", encoding=\"latin1\")\n",
        "df= data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos entonces estas características\n",
        "df = df.drop([\"Nombre\",\"residencia\",\"fecha_nacimiento\",\"fecha_1er_visita\",\"FECHA_INICIO_ACTUAL_EPISODIO\"], axis=1)\n",
        "df = df.dropna(axis=1, how='all')"
      ],
      "metadata": {
        "id": "esYdsyF6PVJs"
      },
      "id": "esYdsyF6PVJs",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos el porcentaje de valores nulos en cada columna\n",
        "null_percentage = (df.isnull().sum() / len(df)) * 100\n",
        "\n",
        "# Con el sguiente código, se crea un DataFrame con los porcentajes de valores nulos\n",
        "null_df = pd.DataFrame({'Columna': null_percentage.index, 'Porcentaje_Null': null_percentage.values})\n",
        "\n",
        "# Filtramos el DataFrame para mantener solo las columnas donde el porcentaje de valores nulos sea menor al 40%\n",
        "columnas_a_mantener = null_df[null_df['Porcentaje_Null'] < 40]['Columna']\n",
        "\n",
        "# Filtramos el DataFrame original para mantener solo las columnas que queremos conservar\n",
        "df = df[columnas_a_mantener]"
      ],
      "metadata": {
        "id": "aDLQ8X1Tozmn"
      },
      "id": "aDLQ8X1Tozmn",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Primero obtenemos las variables que reportan un solo valor y mostramos sus nombres\n",
        "unique_counts = df.nunique()\n",
        "columnas_a_eliminar = unique_counts[unique_counts == 1].index\n",
        "columnas_a_eliminar\n",
        "df = df.drop(columns=columnas_a_eliminar)"
      ],
      "metadata": {
        "id": "MJTeBL1fmCEs"
      },
      "id": "MJTeBL1fmCEs",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_columns = []\n",
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    if len(unique_values) == 2 and all(value in [0, 1] for value in unique_values):\n",
        "        binary_columns.append(column)\n",
        "\n",
        "# Número de columnas con solamente 0's o 1's\n",
        "print(\"Numero de columnas binarias encontradas:\", len(binary_columns))"
      ],
      "metadata": {
        "id": "thcVkgNcRmfE",
        "outputId": "281ec700-e3a9-433d-c38d-baf1be9ff287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "thcVkgNcRmfE",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero de columnas binarias encontradas: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Actualizamos el tipo de las columnas binarias a booleano usando astype()\n",
        "for column in binary_columns:\n",
        "    df[column] = df[column].astype(bool)"
      ],
      "metadata": {
        "id": "cXeYMB32SnjY"
      },
      "id": "cXeYMB32SnjY",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de variables que son en realidad categóricas\n",
        "cat_cols=[\"SEXO\",\"CONDICION_ACTUAL\",\"ESTADO_civil\",\"RELIGION\",\"PROVEEDOR_FAMILIAR\",\"OCUPACIoN_JEFE_FAMILIA\",\"ESCOLARIDAD__JEFE_FAMILIA\",\n",
        "         \"ESCOLARIDAD_MAXIMA_PX\",\"DX_PRIMARIO\",\"CODIGO_DX.1\",\"TRASTORNO_MAYOR_DIAGNOSTICO\",\n",
        "         \"Riesgo_suicidio\",\"Sintomas_ansiosos\"]\n",
        "\n",
        "# Actualizamos el tipo de las columnas categoricas usando astype()\n",
        "for column in cat_cols:\n",
        "    df[column] = df[column].astype(\"category\")"
      ],
      "metadata": {
        "id": "Sh7ne_k76UWz"
      },
      "id": "Sh7ne_k76UWz",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actualizamos el tipo de la columna MENARCA a uno numérico usando astype()\n",
        "df[\"MENARCA\"] = df[\"MENARCA\"].astype(\"float64\")"
      ],
      "metadata": {
        "id": "LwFz8w-Q89Cj"
      },
      "id": "LwFz8w-Q89Cj",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sustituir los valores de MENARCA donde SEXO es \"M\"\n",
        "df.loc[df['SEXO'] == 'M', 'MENARCA'] = -1\n",
        "\n",
        "# Imputar la moda a las variables numéricas\n",
        "for columna in df.select_dtypes(include='number').columns:\n",
        "    df[columna] = df[columna].fillna(df[columna].median())\n",
        "\n",
        "# Imputar la moda a las variables booleanas\n",
        "for columna in df.select_dtypes(include='bool').columns:\n",
        "    moda = df[columna].mode()[0]  # Calcular la moda\n",
        "    df[columna] = df[columna].fillna(moda)\n",
        "\n",
        "# Imputar la moda a las variables alfanuméricas\n",
        "for columna in df.select_dtypes(include='category').columns:\n",
        "    moda = df[columna].mode()[0]  # Calcular la moda\n",
        "    df[columna] = df[columna].fillna(moda)"
      ],
      "metadata": {
        "id": "NTUrQhJ0yUqB"
      },
      "id": "NTUrQhJ0yUqB",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de variables que son en realidad enteros\n",
        "enteros_cols=[\"EDAD_1era_visita\",\"EDAD_INICIO_1er_EPISODIO\",\"AnioS_ESTUDIO_PACIENTE\",\"MENARCA\",\"INICIO_VIDA_SEXUAL_ACTIVA\",\"MADRS_TOTAL\",\"CGI-S.1\"]\n",
        "\n",
        "# Actualizamos el tipo de las columnas de enteros usando astype()\n",
        "for column in enteros_cols:\n",
        "    df[column] = df[column].astype(\"int64\")"
      ],
      "metadata": {
        "id": "i-Z1k2A5_HMW"
      },
      "id": "i-Z1k2A5_HMW",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos estas características\n",
        "df = df.drop([\"EPISODIO_MAYOR_total_vida\",\"SUICIDALIDAD_ACTUAL\",\"SUICIDALIDAD_INTENTO_total_vida\",\n",
        "              \"B1b_INTENCION_DE_MORIR_EN_ACCIDENTE\",\"B5_PENSO_METODO_SUICIDARSE\",\"B8_PENSO_FECHA_SUICIDIO\",\n",
        "              \"B10_INTENCION_SUICIDIO\",\"B18_INTENTO_SUICIDARSE\",\"B2_NECESIDAD_DE_ESTAR_MUERTO\",\"TRASTORNO_MAYOR_PASADO\"],\n",
        "             axis=1)"
      ],
      "metadata": {
        "id": "8hhEnd6h2pzf"
      },
      "id": "8hhEnd6h2pzf",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos estas características\n",
        "df = df.drop([\"CODIGO_DX.1\",\"Puntaje_experto\"],\n",
        "             axis=1)"
      ],
      "metadata": {
        "id": "6ivNtjiUPnqV"
      },
      "id": "6ivNtjiUPnqV",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reemplazar el valor 1955 por la mediana\n",
        "df['EDAD_INICIO_1er_EPISODIO'] = df['EDAD_INICIO_1er_EPISODIO'].replace(1955, df['EDAD_INICIO_1er_EPISODIO'].median())\n",
        "\n",
        "# Reemplazar el valor 1 por la mediana\n",
        "df['INICIO_VIDA_SEXUAL_ACTIVA'] = df['INICIO_VIDA_SEXUAL_ACTIVA'].replace(1, df['INICIO_VIDA_SEXUAL_ACTIVA'].median())"
      ],
      "metadata": {
        "id": "XNERi1gd5zCE"
      },
      "id": "XNERi1gd5zCE",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos una copia del df para realizar una trasnformación\n",
        "df_T=df.copy()"
      ],
      "metadata": {
        "id": "E0shO5sixh2O"
      },
      "id": "E0shO5sixh2O",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Winsonorización:** Reemplaza los valores atípicos con valores en el percentil p-ésimo o (1 - p)-ésimo para reducir su impacto sin eliminarlos."
      ],
      "metadata": {
        "id": "ollbfoh41Bd3"
      },
      "id": "ollbfoh41Bd3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformamos las variables usando Winsonorización\n",
        "df_T['INICIO_VIDA_SEXUAL_ACTIVA_W'] = winsorize(df_T['INICIO_VIDA_SEXUAL_ACTIVA'], limits=(0.05, 0.05))\n",
        "df_T['DURACION_EPISODIO_MAYOR_ACTUAL_W'] = winsorize(df_T['DURACION_EPISODIO_MAYOR_ACTUAL'], limits=(0.05, 0.05))"
      ],
      "metadata": {
        "id": "qQUCHi2g0zJm"
      },
      "id": "qQUCHi2g0zJm",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos estas características originales\n",
        "df_T = df_T.drop([\"INICIO_VIDA_SEXUAL_ACTIVA\",\"DURACION_EPISODIO_MAYOR_ACTUAL\"],\n",
        "             axis=1)"
      ],
      "metadata": {
        "id": "3B5IIskH2EJ8"
      },
      "id": "3B5IIskH2EJ8",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos listas de las variables ordinales\n",
        "cat_orginales= ['ESCOLARIDAD__JEFE_FAMILIA', 'ESCOLARIDAD_MAXIMA_PX', 'DX_PRIMARIO','TRASTORNO_MAYOR_DIAGNOSTICO',\n",
        "                'Riesgo_suicidio','Sintomas_ansiosos']"
      ],
      "metadata": {
        "id": "U7psvMyVncZ8"
      },
      "id": "U7psvMyVncZ8",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una copia del dataframe\n",
        "df_TC=df_T.copy()"
      ],
      "metadata": {
        "id": "n4PyV3p9FmBR"
      },
      "id": "n4PyV3p9FmBR",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el encoder ordinal\n",
        "encoder_1 = OrdinalEncoder(categories=[[\"Menos de 6 años\", \"Primaria\", \"Secundaria\", \"Preparatoria\",\n",
        "                                     \"Estudios universitarios no terminados\", \"Licenciatura\", \"Posgrado\"]], dtype=int)\n",
        "encoder_2 = OrdinalEncoder(categories=[[\"Distimia\",\"Trastorno depresivo episodio único \",\n",
        "                                        \"Trastorno depresivo mayor recidivante\"]], dtype=int)\n",
        "encoder_3 = OrdinalEncoder(categories=[[\"0\",\"TRASTORNO DEPRESIVO MAYOR EPISODIO UNICO\",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR PRIMER EPISODIO\",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR RECURRENTE\",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR RECIDIVANTE \",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR RECURRENTE RESISTENTE\",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR RECURRENTE SEVERO\",\n",
        "                                        \"TRASTORNO DEPRESIVO MAYOR\"]], dtype=int)\n",
        "encoder_4 = OrdinalEncoder(categories=[[\"Leve\",\"Moderado\",\"Alto\"]], dtype=int)\n",
        "encoder_5 = OrdinalEncoder(categories=[[\"Leve\",\"Moderado-Grave\"]], dtype=int)\n",
        "encoder_6 = OrdinalEncoder(categories=[[\"Primera aparición sin antecedente\",\"Indistinguible del pasado\",\n",
        "                                        \"Recurrencia condición previa\",\n",
        "                                        \"Significativamente diferente de condición previa\",\n",
        "                                        \"Exageración de trastorno crónico\"]], dtype=int)\n",
        "\n",
        "# Ajustar y transformar los datos\n",
        "df_TC['ESCOLARIDAD__JEFE_FAMILIA_encoded'] = encoder_1.fit_transform(df_TC[['ESCOLARIDAD__JEFE_FAMILIA']])\n",
        "df_TC['ESCOLARIDAD_MAXIMA_PX_encoded'] = encoder_1.fit_transform(df_TC[['ESCOLARIDAD_MAXIMA_PX']])\n",
        "df_TC['DX_PRIMARIO_encoded'] = encoder_2.fit_transform(df_TC[['DX_PRIMARIO']])\n",
        "df_TC['TRASTORNO_MAYOR_DIAGNOSTICO_encoded'] = encoder_3.fit_transform(df_TC[['TRASTORNO_MAYOR_DIAGNOSTICO']])\n",
        "df_TC['Riesgo_suicidio_encoded'] = encoder_4.fit_transform(df_TC[['Riesgo_suicidio']])\n",
        "df_TC['Sintomas_ansiosos_encoded'] = encoder_5.fit_transform(df_TC[['Sintomas_ansiosos']])\n",
        "df_TC['CONDICION_ACTUAL_encoded'] = encoder_6.fit_transform(df_TC[['CONDICION_ACTUAL']])"
      ],
      "metadata": {
        "id": "fF7ve2zfCYHG"
      },
      "id": "fF7ve2zfCYHG",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos estas características originales\n",
        "df_TC = df_TC.drop([\"ESCOLARIDAD__JEFE_FAMILIA\",\"ESCOLARIDAD_MAXIMA_PX\",\"DX_PRIMARIO\",\"TRASTORNO_MAYOR_DIAGNOSTICO\",\n",
        "                \"Riesgo_suicidio\",\"Sintomas_ansiosos\",\"CONDICION_ACTUAL\"],\n",
        "             axis=1)"
      ],
      "metadata": {
        "id": "D2-XKzz-DKuI"
      },
      "id": "D2-XKzz-DKuI",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos listas de las variables no ordinales\n",
        "cat_no_orginales= ['SEXO', 'ESTADO_civil', 'RELIGION','PROVEEDOR_FAMILIAR', 'OCUPACIoN_JEFE_FAMILIA']"
      ],
      "metadata": {
        "id": "73NCIXxVJ17m"
      },
      "id": "73NCIXxVJ17m",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una copia del ultimo dataframe\n",
        "df_TCL=df_TC.copy()"
      ],
      "metadata": {
        "id": "oH_Ynl1uKwNm"
      },
      "id": "oH_Ynl1uKwNm",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar el LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Iterar sobre las columnas y aplicar el LabelEncoder\n",
        "for col in cat_no_orginales:\n",
        "    df_TCL[col] = encoder.fit_transform(df_TCL[col])"
      ],
      "metadata": {
        "id": "wq4GGnTPJ-2O"
      },
      "id": "wq4GGnTPJ-2O",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una copia del ultimo dataframe\n",
        "df_TC_encoded=df_TC.copy()"
      ],
      "metadata": {
        "id": "yAoibeaaLwUV"
      },
      "id": "yAoibeaaLwUV",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar Get_dummies asegurando de eliminar la primera categoría\n",
        "df_TC_encoded = pd.get_dummies(df_TC_encoded, columns=cat_no_orginales, drop_first=True)"
      ],
      "metadata": {
        "id": "VDqQrNrSLI67"
      },
      "id": "VDqQrNrSLI67",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Modelos supervisados"
      ],
      "metadata": {
        "id": "nDfq3k1O-bp6"
      },
      "id": "nDfq3k1O-bp6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comanzaremos con una observación importante, el proyecto con el que estamos trabajando tiene que ver con la salud mental y física de pacientes, por lo que la métrica más adecuada para nuestros fines será **RECALL**, con el objetivo de evitar los falsos negativos en la medida de lo posible. No obstante, también mostraremos la métrica F1 como referencia para que, de ser posible y sin ser el objetivo principal, se minimicen los falsos positivos.\n",
        "\n",
        "Para esta etapa del proyecto profundizamos un poco más en los 7 modelos supervisados que elegimos probar.\n",
        "\n",
        "* **Regresión logística.** Este es un modelo simple y fácil de interpretar. Además, el modelo obtiene las probabilidades de pertenencia a cada clase, lo que puede servir para realizar umbrales más laxos o reestrictivos.\n",
        "* **SVM.** Este algoritmo funciona bien aún con un número grande de características y, aunque la base con dummies no es gigante, al final tenemos 69 variables.\n",
        "* **KNN.** Fácil entender e implementar.\n",
        "* **Árbol de Decisión.** Elefimos este porque es muy fácil de interpretar y se puede visualizar, además de que funciona bastante bien sin la necesidad de realizar tantas transformaciones a los datos, lo que muchas veces dificulta la interpretación.\n",
        "* **Bosque Aleatorio.** Al realizar la agregación de múltiples árboles de decisión, ayuda a reducir el riesgo de sobreajuste.\n",
        "* **Red neuronal.** Este algoritmo es potente para problemas con relaciones no lineales y complejas al descubrir patrones complejos. No obstante, su interpretación no es transparente.\n",
        "* **XGBoost.** Este algoritmo suele obtener una precisión muy alta y con el uso de boosting evita el sobreajuste y mejorara la generalización en datos no vistos. Gracias a lo anterior con este algoritmo se han ganado muchas competiciones de machine learning.\n",
        "\n",
        "Dividimos los modelos anteriores en dos grupos, ya que algunos de ellos necesitan que los datos tengan algunas transformaciones particulares para poder procesar y modelar adecuadamente la información de las variables categóricas en sus cálculos y predicciones."
      ],
      "metadata": {
        "id": "32Hynfnjy-tk"
      },
      "id": "32Hynfnjy-tk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Regresión logística, SVM y KNN"
      ],
      "metadata": {
        "id": "sZm-rIy4H5Q8"
      },
      "id": "sZm-rIy4H5Q8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para estos modelos utilizaremos la base con variables dummies, observamos que esta base consta de 69 variables y 380 observaciones"
      ],
      "metadata": {
        "id": "1LT4CqbR7CTH"
      },
      "id": "1LT4CqbR7CTH"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataframe usando get dummies tiene {df_TC_encoded.shape[1]} columnas.\")\n",
        "print(f\"Dataframe usando get dummies tiene {df_TC_encoded.shape[0]} renglones.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky2oZZpUwp_t",
        "outputId": "457fbf4a-2c22-4798-8f96-4b6a64964716"
      },
      "id": "Ky2oZZpUwp_t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe usando get dummies tiene 69 columnas.\n",
            "Dataframe usando get dummies tiene 380 renglones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generamos la base con las características y la variable de salida\n",
        "X1 = df_TC_encoded.drop(columns=['Sintomas_ansiosos_encoded'])\n",
        "Y1 = df_TC_encoded['Sintomas_ansiosos_encoded']"
      ],
      "metadata": {
        "id": "a-4u7zefwCJ8"
      },
      "id": "a-4u7zefwCJ8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque nuestra base es pequeña, debemos de dividirla para obtener datos de entrenamiento y validación. Así, usaremos el 90% de los datos para entrenar los modelos."
      ],
      "metadata": {
        "id": "isTyiFIO7qfI"
      },
      "id": "isTyiFIO7qfI"
    },
    {
      "cell_type": "code",
      "source": [
        "Xtv1, Xtest1, ytv1, ytest1 = train_test_split(X1, Y1, train_size = 0.9, random_state = 0)"
      ],
      "metadata": {
        "id": "K0aNz3m8sRFV"
      },
      "id": "K0aNz3m8sRFV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1 Regresión logística"
      ],
      "metadata": {
        "id": "o0DY_0cBwIPE"
      },
      "id": "o0DY_0cBwIPE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "reg = LogisticRegression(solver='liblinear', class_weight= \"balanced\", random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2', 'none'],\n",
        "    #'C': [0.001, 0.01, 0.1],\n",
        "    'max_iter': [100, 200, 300],\n",
        "    'tol': [1e-4, 1e-3, 1e-2, 1e-1]\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=reg,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv1, ytv1)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv1_pred = cross_val_predict(grid.best_estimator_, Xtv1, ytv1, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv1, ytv1_pred)\n",
        "recall_tv = recall_score(ytv1, ytv1_pred, average='binary')\n",
        "f1_tv = f1_score(ytv1, ytv1_pred, average='binary')\n",
        "cm_tv = confusion_matrix(ytv1, ytv1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"F1 Score: {f1_tv:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest1_pred = grid.best_estimator_.predict(Xtest1)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest1, ytest1_pred)\n",
        "recall_test = recall_score(ytest1, ytest1_pred, average='binary')\n",
        "f1_test = f1_score(ytest1, ytest1_pred, average='binary')\n",
        "cm_test = confusion_matrix(ytest1, ytest1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"F1 Score: {f1_test:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrsOVi7EuaoN",
        "outputId": "0d77454c-d022-47eb-bde5-6e486df0196b"
      },
      "id": "FrsOVi7EuaoN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.5731\n",
            "Recall: 0.5973\n",
            "F1 Score: 0.6439\n",
            "Confusion Matrix:\n",
            "[[ 64  57]\n",
            " [ 89 132]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.6053\n",
            "Recall: 0.6250\n",
            "F1 Score: 0.6667\n",
            "Confusion Matrix:\n",
            "[[ 8  6]\n",
            " [ 9 15]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2 SVM"
      ],
      "metadata": {
        "id": "1PJFmKvW91PL"
      },
      "id": "1PJFmKvW91PL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tardó 28 minutos con los parámetros que están comentados y así me da recall de 1..."
      ],
      "metadata": {
        "id": "Qr0yQaO0FKG2"
      },
      "id": "Qr0yQaO0FKG2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "svm = SVC(class_weight='balanced',random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1],\n",
        "#    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
        "    'gamma': [0.001, 0.01, 0.1],\n",
        "#    'degree': [2, 3, 4]\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=svm,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv1, ytv1)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv1_pred = cross_val_predict(grid.best_estimator_, Xtv1, ytv1, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv1, ytv1_pred)\n",
        "recall_tv = recall_score(ytv1, ytv1_pred, average='binary')\n",
        "f1_tv = f1_score(ytv1, ytv1_pred, average='binary')\n",
        "cm_tv = confusion_matrix(ytv1, ytv1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"F1 Score: {f1_tv:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest1_pred = grid.best_estimator_.predict(Xtest1)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest1, ytest1_pred)\n",
        "recall_test = recall_score(ytest1, ytest1_pred, average='binary')\n",
        "f1_test = f1_score(ytest1, ytest1_pred, average='binary')\n",
        "cm_test = confusion_matrix(ytest1, ytest1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"F1 Score: {f1_test:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnwt7-oF95wa",
        "outputId": "80502030-137f-49fa-f90e-b3df3329de86"
      },
      "id": "jnwt7-oF95wa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'C': 0.001, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.6023\n",
            "Recall: 0.6561\n",
            "F1 Score: 0.6808\n",
            "Confusion Matrix:\n",
            "[[ 61  60]\n",
            " [ 76 145]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.5263\n",
            "Recall: 0.5417\n",
            "F1 Score: 0.5909\n",
            "Confusion Matrix:\n",
            "[[ 7  7]\n",
            " [11 13]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.3 KNN"
      ],
      "metadata": {
        "id": "YFmBsXgkGPgT"
      },
      "id": "YFmBsXgkGPgT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=knn,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv1, ytv1)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv1_pred = cross_val_predict(grid.best_estimator_, Xtv1, ytv1, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv1, ytv1_pred)\n",
        "recall_tv = recall_score(ytv1, ytv1_pred, average='binary')\n",
        "f1_tv = f1_score(ytv1, ytv1_pred, average='binary')\n",
        "cm_tv = confusion_matrix(ytv1, ytv1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"F1 Score: {f1_tv:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest1_pred = grid.best_estimator_.predict(Xtest1)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest1, ytest1_pred)\n",
        "recall_test = recall_score(ytest1, ytest1_pred, average='binary')\n",
        "f1_test = f1_score(ytest1, ytest1_pred, average='binary')\n",
        "cm_test = confusion_matrix(ytest1, ytest1_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"F1 Score: {f1_test:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCFNfGe8GR45",
        "outputId": "f8f9232a-6e50-45c6-f283-a6e4023602b7"
      },
      "id": "SCFNfGe8GR45",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'algorithm': 'auto', 'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.6053\n",
            "Recall: 0.8235\n",
            "F1 Score: 0.7295\n",
            "Confusion Matrix:\n",
            "[[ 25  96]\n",
            " [ 39 182]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.5526\n",
            "Recall: 0.7500\n",
            "F1 Score: 0.6792\n",
            "Confusion Matrix:\n",
            "[[ 3 11]\n",
            " [ 6 18]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Árbol de decisión, Bosque aleatorio, Red neuronal, XGBoost"
      ],
      "metadata": {
        "id": "s8psjMu9HgO_"
      },
      "id": "s8psjMu9HgO_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora probaremos con otro tipo de modelos en los que no es necesario utilizar variables dummies. Observamos que esta base consta de 39 variables y 380 observaciones"
      ],
      "metadata": {
        "id": "pq8WZBjgHrJd"
      },
      "id": "pq8WZBjgHrJd"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataframe usando label ecoding tiene {df_TCL.shape[1]} columnas.\")\n",
        "print(f\"Dataframe usando label ecoding tiene {df_TCL.shape[0]} renglones.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o7_VkwLHvOa",
        "outputId": "0e70ee9d-11fe-4198-c51a-c3eb612d077b"
      },
      "id": "_o7_VkwLHvOa",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe usando label ecoding tiene 39 columnas.\n",
            "Dataframe usando label ecoding tiene 380 renglones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generamos la base con las características y la variable de salida\n",
        "X2 = df_TCL.drop(columns=['Sintomas_ansiosos_encoded'])\n",
        "Y2 = df_TCL['Sintomas_ansiosos_encoded']"
      ],
      "metadata": {
        "id": "s45wkU0HH6uh"
      },
      "id": "s45wkU0HH6uh",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como ya explicamos anteriormente, utilizaremos el 90% de los datos para el entrenamiento además de validación cruzada."
      ],
      "metadata": {
        "id": "akHik_TjH7uS"
      },
      "id": "akHik_TjH7uS"
    },
    {
      "cell_type": "code",
      "source": [
        "Xtv2, Xtest2, ytv2, ytest2 = train_test_split(X2, Y2, train_size = 0.9, random_state = 0)"
      ],
      "metadata": {
        "id": "1KrMnEPvH6w5"
      },
      "id": "1KrMnEPvH6w5",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1 Árbol de decisión"
      ],
      "metadata": {
        "id": "qgE2uXSAHjsG"
      },
      "id": "qgE2uXSAHjsG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "arbol = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_split': [7, 10, 15],\n",
        "    'min_samples_leaf': [7, 10, 15],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=arbol,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv2, ytv2)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv2_pred = cross_val_predict(grid.best_estimator_, Xtv2, ytv2, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv2, ytv2_pred)\n",
        "recall_tv = recall_score(ytv2, ytv2_pred, average='binary')\n",
        "f1_tv = f1_score(ytv2, ytv2_pred, average='binary')\n",
        "cm_tv = confusion_matrix(ytv2, ytv2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"F1 Score: {f1_tv:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest2_pred = grid.best_estimator_.predict(Xtest2)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest2, ytest2_pred)\n",
        "recall_test = recall_score(ytest2, ytest2_pred, average='binary')\n",
        "f1_test = f1_score(ytest2, ytest2_pred, average='binary')\n",
        "cm_test = confusion_matrix(ytest2, ytest2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"F1 Score: {f1_test:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uNE9YV4KGlQ",
        "outputId": "445b4d75-aec0-4295-af9c-82eb56094eab"
      },
      "id": "9uNE9YV4KGlQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 7}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.6082\n",
            "Recall: 0.9276\n",
            "F1 Score: 0.7537\n",
            "Confusion Matrix:\n",
            "[[  3 118]\n",
            " [ 16 205]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.5789\n",
            "Recall: 0.9167\n",
            "F1 Score: 0.7333\n",
            "Confusion Matrix:\n",
            "[[ 0 14]\n",
            " [ 2 22]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2 Bosque aleatorio"
      ],
      "metadata": {
        "id": "So9HF0T7J4bJ"
      },
      "id": "So9HF0T7J4bJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "bosque = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_split': [7, 10, 15],\n",
        "    'min_samples_leaf': [7, 10, 15],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=bosque,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv2, ytv2)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv2_pred = cross_val_predict(grid.best_estimator_, Xtv2, ytv2, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv2, ytv2_pred)\n",
        "recall_tv = recall_score(ytv2, ytv2_pred, average='binary')\n",
        "f1_tv = f1_score(ytv2, ytv2_pred, average='binary')\n",
        "cm_tv = confusion_matrix(ytv2, ytv2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"F1 Score: {f1_tv:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest2_pred = grid.best_estimator_.predict(Xtest2)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest2, ytest2_pred)\n",
        "recall_test = recall_score(ytest2, ytest2_pred, average='binary')\n",
        "f1_test = f1_score(ytest2, ytest2_pred, average='binary')\n",
        "cm_test = confusion_matrix(ytest2, ytest2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"F1 Score: {f1_test:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptKvu9WLHbTB",
        "outputId": "f50a700d-718a-43ec-d500-9980c4173458"
      },
      "id": "ptKvu9WLHbTB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 15, 'min_samples_split': 7, 'n_estimators': 100}\n",
            "Resultados en el conjunto de validación:\n",
            "Accuracy: 0.6374\n",
            "Recall: 0.9729\n",
            "F1 Score: 0.7762\n",
            "Confusion Matrix:\n",
            "[[  3 118]\n",
            " [  6 215]]\n",
            "\n",
            "Resultados en el conjunto de prueba:\n",
            "Accuracy: 0.6579\n",
            "Recall: 0.9583\n",
            "F1 Score: 0.7797\n",
            "Confusion Matrix:\n",
            "[[ 2 12]\n",
            " [ 1 23]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.3 Red neuronal"
      ],
      "metadata": {
        "id": "0qsWeT2MWVLE"
      },
      "id": "0qsWeT2MWVLE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "red = MLPClassifier(solver=\"adam\", random_state=0)\n",
        "\n",
        "# Vamos a probar estos hiperparámetros\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
        "    'activation': ['logistic', 'tanh', 'relu'],\n",
        "    'alpha': [0.001, 0.01, 0.1],\n",
        "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
        "    'max_iter': [200, 400, 600]\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
        "\n",
        "grid = GridSearchCV(estimator=red,\n",
        "                  param_grid=param_grid,\n",
        "                  cv=cv,\n",
        "                  scoring=\"recall\")\n",
        "\n",
        "# se ajusta el modelo\n",
        "grid.fit(Xtv2, ytv2)\n",
        "\n",
        "# Imprimimos los mejores hiperparámetros encontrados\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Obtenemos el rendimiento del modelo con el conjunto de entrenamiento usando validación cruzada\n",
        "ytv2_pred = cross_val_predict(grid.best_estimator_, Xtv2, ytv2, cv=5)\n",
        "\n",
        "accuracy_tv = accuracy_score(ytv2, ytv2_pred)\n",
        "recall_tv = recall_score(ytv2, ytv2_pred, average='binary')\n",
        "f1_tv = f1_score(ytv2, ytv2_pred, average='binary')\n",
        "cm_tv = confusion_matrix(ytv2, ytv2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de validación:\")\n",
        "print(f\"Accuracy: {accuracy_tv:.4f}\")\n",
        "print(f\"Recall: {recall_tv:.4f}\")\n",
        "print(f\"F1 Score: {f1_tv:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_tv}\\n')\n",
        "\n",
        "# ahora obtenemos el resultado con el conjunto de prueba\n",
        "ytest2_pred = grid.best_estimator_.predict(Xtest2)\n",
        "\n",
        "accuracy_test = accuracy_score(ytest2, ytest2_pred)\n",
        "recall_test = recall_score(ytest2, ytest2_pred, average='binary')\n",
        "f1_test = f1_score(ytest2, ytest2_pred, average='binary')\n",
        "cm_test = confusion_matrix(ytest2, ytest2_pred)\n",
        "\n",
        "print(\"Resultados en el conjunto de prueba:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"F1 Score: {f1_test:.4f}\")\n",
        "print(f'Confusion Matrix:\\n{cm_test}\\n')"
      ],
      "metadata": {
        "id": "_u-o-gR6HbV5"
      },
      "id": "_u-o-gR6HbV5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oo9c_BpMHbYR"
      },
      "id": "oo9c_BpMHbYR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Conclusiones"
      ],
      "metadata": {
        "id": "c8oC5CN8aZYz"
      },
      "id": "c8oC5CN8aZYz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al ajustar los hiperparámetros de los 7 modelos supervisados elegidos, obtivimos diferentes resultados a los de la entrega anterior. Si bien, en algunos casos el rendimiento cayó y en algunos otros fue mejor (el rendimiento obtenido la semana previa sin el refinamiento de hiperparámetros se mostrará entre paréntesis), en todos los modelos notamos un mucho mejor comportamiento en cuanto al sobreajuste.\n",
        "\n",
        "Así, al realizar la busqueda de algunos de los mejores hiperparámetros:\n",
        "\n",
        "* Para la regresión logística obtuvimos un recall de 60% y 62% con el conjunto de entrenamiento y el de validación respectivamente (75% en la entrega anterior). Si bien, se esperaría que el rendimiento fuera mejor en el conjunto de entrenamiento, una diferencia del 2% es relativamente pequeña y podría estar dentro del margen de error.\n",
        "\n",
        "* En cuanto a SVM obtenemos 65% en el entrenamiento (60% en la entrega anterior), y aún habiendo probado hiperparámetros para intentar evitar el sobreajuste, al utilizar los datos de prueba notamos que el rendimiento bajó considerablemente por lo que el modelo parece estar sobreentrenado.\n",
        "\n",
        "* Con KNN obtuvimos 82% y 75% de rendimiento con el conjunto de entrenamiento y el de validación respectivamente (75% y 62% en la entrega anterior). Aunque obtuvimos mucho mejores resultados al refinar los hiperparámetros, aún tenemos un problema de sobreentrenamiento, si bien mucho menor que la semana anterior.\n",
        "\n",
        "* Con árboles de decisión obtuvimos una recall de 93% y 92%, con los conjuntos de entrenamiento y prueba, respectivamente (70% y 75% en la entrega anterior). Además el F1 también es bastante aceptable 75% con el conjunto de entrenamiento y 73% con el de prueba. Lo anterior, representa una mejoría considerable con respecto al rendimiento obtenido la semana previa, en donde además, teníamos sobreajuste.\n",
        "\n",
        "* Con el bosque aleatorio tuvimos resultados ligeramente mejores al árbol de decisión. Obtuvimos un recall de 97% en el entrenamiento y 96% con el conjunto de prueba (83% y 87% en la entrega anterior), y un F1 de 78% con ambos conjuntos de datos. Al igual que con el árbol de decisión, al refinar los hiperparámetros obtuvimos mejores resultados que la semana previa además de, al parecer, evitar el sobreajuste.\n"
      ],
      "metadata": {
        "id": "f3f-vUnQtWg_"
      },
      "id": "f3f-vUnQtWg_"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4oIRZ5ycHAh0"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}